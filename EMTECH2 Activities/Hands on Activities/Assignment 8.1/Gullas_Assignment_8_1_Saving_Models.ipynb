{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Name: Gullas Rainer L.\n",
        "\n",
        "# Section: BSCPE32S3\n",
        "\n",
        "#Date Perfomred: 04/15/2024\n",
        "\n",
        "#Date Submitted: 04/19/2024\n",
        "\n",
        "#Instructor: Engr. Roman Richard"
      ],
      "metadata": {
        "id": "xSfx6xQj9Cq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4gOOtSl-RREw",
        "outputId": "70babfa6-c8df-4c6d-f953-d67195d5bc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "wine = fetch_ucirepo(id=109)\n",
        "\n",
        "X = wine.data.features\n",
        "y = wine.data.targets\n",
        "\n",
        "print(wine.metadata)\n",
        "print(wine.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SvknJs_ocHiW",
        "outputId": "d174193f-51c4-4139-b95a-3361165b0856"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 109, 'name': 'Wine', 'repository_url': 'https://archive.ics.uci.edu/dataset/109/wine', 'data_url': 'https://archive.ics.uci.edu/static/public/109/data.csv', 'abstract': 'Using chemical analysis to determine the origin of wines', 'area': 'Physics and Chemistry', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 178, 'num_features': 13, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1992, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C5PC7J', 'creators': ['Stefan Aeberhard', 'M. Forina'], 'intro_paper': {'title': 'Comparative analysis of statistical pattern recognition methods in high dimensional settings', 'authors': 'S. Aeberhard, D. Coomans, O. Vel', 'published_in': 'Pattern Recognition', 'year': 1994, 'url': 'https://www.semanticscholar.org/paper/83dc3e4030d7b9fbdbb4bde03ce12ab70ca10528', 'doi': '10.1016/0031-3203(94)90145-7'}, 'additional_info': {'summary': 'These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. \\r\\n\\r\\nI think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.)  I lost it, and b.), I would not know which 13 variables are included in the set.\\r\\n\\r\\nThe attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it )\\r\\n1) Alcohol\\r\\n2) Malic acid\\r\\n3) Ash\\r\\n4) Alcalinity of ash  \\r\\n5) Magnesium\\r\\n6) Total phenols\\r\\n7) Flavanoids\\r\\n8) Nonflavanoid phenols\\r\\n9) Proanthocyanins\\r\\n10)Color intensity\\r\\n11)Hue\\r\\n12)OD280/OD315 of diluted wines\\r\\n13)Proline \\r\\n\\r\\nIn a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging.           ', 'purpose': 'test', 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'All attributes are continuous\\r\\n\\t\\r\\nNo statistics available, but suggest to standardise variables for certain uses (e.g. for us with classifiers which are NOT scale invariant)\\r\\n\\r\\nNOTE: 1st attribute is class identifier (1-3)', 'citation': None}}\n",
            "                            name     role         type demographic  \\\n",
            "0                          class   Target  Categorical        None   \n",
            "1                        Alcohol  Feature   Continuous        None   \n",
            "2                      Malicacid  Feature   Continuous        None   \n",
            "3                            Ash  Feature   Continuous        None   \n",
            "4              Alcalinity_of_ash  Feature   Continuous        None   \n",
            "5                      Magnesium  Feature      Integer        None   \n",
            "6                  Total_phenols  Feature   Continuous        None   \n",
            "7                     Flavanoids  Feature   Continuous        None   \n",
            "8           Nonflavanoid_phenols  Feature   Continuous        None   \n",
            "9                Proanthocyanins  Feature   Continuous        None   \n",
            "10               Color_intensity  Feature   Continuous        None   \n",
            "11                           Hue  Feature   Continuous        None   \n",
            "12  0D280_0D315_of_diluted_wines  Feature   Continuous        None   \n",
            "13                       Proline  Feature      Integer        None   \n",
            "\n",
            "   description units missing_values  \n",
            "0         None  None             no  \n",
            "1         None  None             no  \n",
            "2         None  None             no  \n",
            "3         None  None             no  \n",
            "4         None  None             no  \n",
            "5         None  None             no  \n",
            "6         None  None             no  \n",
            "7         None  None             no  \n",
            "8         None  None             no  \n",
            "9         None  None             no  \n",
            "10        None  None             no  \n",
            "11        None  None             no  \n",
            "12        None  None             no  \n",
            "13        None  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jad0HoQhtuhw",
        "outputId": "f710cada-4861-4cd4-9954-ba714cdee953"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
              "0      14.23       1.71  2.43               15.6        127           2.80   \n",
              "1      13.20       1.78  2.14               11.2        100           2.65   \n",
              "2      13.16       2.36  2.67               18.6        101           2.80   \n",
              "3      14.37       1.95  2.50               16.8        113           3.85   \n",
              "4      13.24       2.59  2.87               21.0        118           2.80   \n",
              "..       ...        ...   ...                ...        ...            ...   \n",
              "173    13.71       5.65  2.45               20.5         95           1.68   \n",
              "174    13.40       3.91  2.48               23.0        102           1.80   \n",
              "175    13.27       4.28  2.26               20.0        120           1.59   \n",
              "176    13.17       2.59  2.37               20.0        120           1.65   \n",
              "177    14.13       4.10  2.74               24.5         96           2.05   \n",
              "\n",
              "     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     0D280_0D315_of_diluted_wines  Proline  \n",
              "0                            3.92     1065  \n",
              "1                            3.40     1050  \n",
              "2                            3.17     1185  \n",
              "3                            3.45     1480  \n",
              "4                            2.93      735  \n",
              "..                            ...      ...  \n",
              "173                          1.74      740  \n",
              "174                          1.56      750  \n",
              "175                          1.56      835  \n",
              "176                          1.62      840  \n",
              "177                          1.60      560  \n",
              "\n",
              "[178 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5f1ef48-b707-4f66-9ef6-b30d325ff405\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malicacid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity_of_ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total_phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid_phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color_intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>0D280_0D315_of_diluted_wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5f1ef48-b707-4f66-9ef6-b30d325ff405')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5f1ef48-b707-4f66-9ef6-b30d325ff405 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5f1ef48-b707-4f66-9ef6-b30d325ff405');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77a3a72f-e648-4f0d-a70d-6927de181506\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77a3a72f-e648-4f0d-a70d-6927de181506')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77a3a72f-e648-4f0d-a70d-6927de181506 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 178,\n  \"fields\": [\n    {\n      \"column\": \"Alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8118265380058575,\n        \"min\": 11.03,\n        \"max\": 14.83,\n        \"num_unique_values\": 126,\n        \"samples\": [\n          11.62,\n          13.64,\n          13.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Malicacid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1171460976144627,\n        \"min\": 0.74,\n        \"max\": 5.8,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          1.21,\n          2.83,\n          1.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27434400906081485,\n        \"min\": 1.36,\n        \"max\": 3.23,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          2.31,\n          2.43,\n          2.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alcalinity_of_ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.339563767173505,\n        \"min\": 10.6,\n        \"max\": 30.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          25.5,\n          28.5,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Magnesium\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 70,\n        \"max\": 162,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          126,\n          85,\n          162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6258510488339893,\n        \"min\": 0.98,\n        \"max\": 3.88,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          1.68,\n          2.11,\n          1.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flavanoids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9988586850169467,\n        \"min\": 0.34,\n        \"max\": 5.08,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          3.18,\n          2.5,\n          3.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nonflavanoid_phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12445334029667937,\n        \"min\": 0.13,\n        \"max\": 0.66,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.58,\n          0.41,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proanthocyanins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5723588626747613,\n        \"min\": 0.41,\n        \"max\": 3.58,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.75,\n          1.77,\n          1.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Color_intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.318285871822413,\n        \"min\": 1.28,\n        \"max\": 13.0,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          2.95,\n          3.3,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22857156582982338,\n        \"min\": 0.48,\n        \"max\": 1.71,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          1.22,\n          1.04,\n          1.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0D280_0D315_of_diluted_wines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7099904287650504,\n        \"min\": 1.27,\n        \"max\": 4.0,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          4.0,\n          1.82,\n          1.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314,\n        \"min\": 278,\n        \"max\": 1680,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          1375,\n          1270,\n          735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "s7Fptky6FGaq",
        "outputId": "d67dddea-1240-4b88-8125-b77da59be230"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     class\n",
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        1\n",
              "4        1\n",
              "..     ...\n",
              "173      3\n",
              "174      3\n",
              "175      3\n",
              "176      3\n",
              "177      3\n",
              "\n",
              "[178 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd670db7-c433-4653-b606-890c69f197d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd670db7-c433-4653-b606-890c69f197d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd670db7-c433-4653-b606-890c69f197d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd670db7-c433-4653-b606-890c69f197d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6cf49ef7-fe11-41b9-b1db-d2db8d18714f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cf49ef7-fe11-41b9-b1db-d2db8d18714f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6cf49ef7-fe11-41b9-b1db-d2db8d18714f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y",
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 178,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import make_classification"
      ],
      "metadata": {
        "id": "AihcxBlRtu_R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = X.isnull().sum()\n",
        "\n",
        "print(null_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aoaLQqam7ScK",
        "outputId": "abf408ef-ef3a-42d9-f1bc-73f9cbc0fab5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alcohol                         0\n",
            "Malicacid                       0\n",
            "Ash                             0\n",
            "Alcalinity_of_ash               0\n",
            "Magnesium                       0\n",
            "Total_phenols                   0\n",
            "Flavanoids                      0\n",
            "Nonflavanoid_phenols            0\n",
            "Proanthocyanins                 0\n",
            "Color_intensity                 0\n",
            "Hue                             0\n",
            "0D280_0D315_of_diluted_wines    0\n",
            "Proline                         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = X.isnull().sum()\n",
        "\n",
        "print(null_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_h88byC37pAI",
        "outputId": "e4a12a6f-b160-4dbf-ef8c-75cfe748c605"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alcohol                         0\n",
            "Malicacid                       0\n",
            "Ash                             0\n",
            "Alcalinity_of_ash               0\n",
            "Magnesium                       0\n",
            "Total_phenols                   0\n",
            "Flavanoids                      0\n",
            "Nonflavanoid_phenols            0\n",
            "Proanthocyanins                 0\n",
            "Color_intensity                 0\n",
            "Hue                             0\n",
            "0D280_0D315_of_diluted_wines    0\n",
            "Proline                         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_1 = X.iloc[:, 0].values\n",
        "y_1 = y[\"class\"].values"
      ],
      "metadata": {
        "id": "uvoJ52meE_A_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the Model as HDF5 format"
      ],
      "metadata": {
        "id": "PMJ3xi3rYZom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import h5py\n",
        "import tempfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "a8Ud2S5XV3qg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "from keras.layers import GaussianNoise\n",
        "input_shape = (X_train_norm.shape[1],)\n",
        "model = Sequential([\n",
        "    Dense(10, input_shape=input_shape, activation='relu'),\n",
        "    GaussianNoise(0.5),\n",
        "    Dense(3, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "J_zMZnLGW8B6"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0izU5tedva3p",
        "outputId": "e44145d9-a68e-4a02-99b0-f0ba3733c338"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d37055beb90>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kJ3RNthEviH7",
        "outputId": "8772c1d3-94ff-470e-cfcb-4a891b5e2104"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 19.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mqe7b0X7vxjo",
        "outputId": "c8e128e7-405f-4eda-b903-ae9c0875a803"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the model as JSON and YMAL format"
      ],
      "metadata": {
        "id": "tFtMWQNnYgaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import yaml"
      ],
      "metadata": {
        "id": "mnkW3AczYYU3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open('classification_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "from keras.models import model_from_json\n",
        "with open(\"classification_model.json\", \"r\") as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "loaded_model = load_model(\"/content/classification_model.h5\")\n",
        "\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "scores_loaded = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy (Loaded Model): %.2f%%\" % (scores_loaded[1] * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aow8HCH-YoPX",
        "outputId": "624af5d2-e9ea-459a-9f31-a48b8b9e6e9b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (Loaded Model): 19.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_file_path = '/content/classification_model.json'\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(\"/content/classification_model.h5\")\n",
        "\n",
        "loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "scores_loaded = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy (Loaded Model): %.2f%%\" % (scores_loaded[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lR5Zs1HhYyT0",
        "outputId": "37fd8bbb-dc69-470d-bd66-9b319077e4e1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 321 calls to <function Model.make_test_function.<locals>.test_function at 0x7d3706de4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (Loaded Model): 19.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint Neural Network Model Improvements"
      ],
      "metadata": {
        "id": "h8j2XlRMdU4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only = True)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(X, y, validation_split = 0.33, epochs = 50, batch_size = 10, callbacks = callbacks_list, verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vWxaGWYtdUc_",
        "outputId": "0c74cc62-7bd6-48df-c69e-e4869d65e095"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to weights-improvement-01-0.00.keras\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.00000\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checkpoint Best Neural Network Model only"
      ],
      "metadata": {
        "id": "Z__14fMLeKoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Created model and loaded weights from file\")\n",
        "scores = model.evaluate(X, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QUpcmMLgeFh6",
        "outputId": "e2c72407-3361-4078-c7f1-ea9dbbb9aefc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model and loaded weights from file\n",
            "accuracy: 33.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize Model Training History in Keras"
      ],
      "metadata": {
        "id": "GNcYhIV10iEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "PEi6tN2ze_tb",
        "outputId": "af3184ed-b131-4836-d6a9-700f8cbe8108"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3y0lEQVR4nO3de1xVdb7/8ffmDiIXBUERwVteSjFFDS/pJMV0cbJMqWkCqfRMaqnkTJolpnPCmixLHXXmjDWVpWnZdBvLyMtk5AXzfikZFVMBSQUBBdx7/f7o557ZAxZsN2xZvp6Px3rE/q7vWuuzv+M5+/1Y67vWshiGYQgAAMAkPNxdAAAAgCsRbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgC4zOHDh2WxWPTaa6/Vedt169bJYrFo3bp1Lq8LwNWFcAMAAEyFcAMAAEyFcAMA9aisrMzdJQBXHcINYCIzZsyQxWLRt99+q9/85jcKDg5WeHi4nn76aRmGoaNHj+rOO+9UUFCQIiMjNWfOnGr7KCws1EMPPaSIiAj5+fkpLi5Of/vb36r1O3PmjEaNGqXg4GCFhIQoNTVVZ86cqbGu/fv365577lGzZs3k5+en+Ph4ffDBB059xyNHjmjs2LHq1KmT/P391bx5c40YMUKHDx+uscZJkyYpNjZWvr6+at26tVJSUlRUVGTvc/78ec2YMUPXXHON/Pz81LJlS919993Kzc2VdOm5QDXNLxo1apQCAwOVm5ur2267TU2bNtX9998vSfrnP/+pESNGqE2bNvL19VV0dLQmTZqkc+fO1TheI0eOVHh4uPz9/dWpUydNmzZNkrR27VpZLBatWrWq2nZvvfWWLBaLsrOz6zqsgKl4ubsAAK6XnJysLl26aPbs2fr444/1hz/8Qc2aNdPixYt100036bnnntPSpUs1efJk9e7dWzfeeKMk6dy5cxo8eLAOHjyo8ePHq23btlqxYoVGjRqlM2fOaMKECZIkwzB055136ssvv9Rvf/tbdenSRatWrVJqamq1Wvbs2aP+/fsrKipKU6ZMUZMmTfTOO+9o2LBhevfdd3XXXXfV6btt2bJFX331le699161bt1ahw8f1sKFCzV48GDt3btXAQEBkqTS0lINHDhQ+/bt04MPPqiePXuqqKhIH3zwgb7//nuFhYXJarXqjjvuUFZWlu69915NmDBBZ8+e1Zo1a7R79261b9++zmN/4cIFJSUlacCAAXrhhRfs9axYsULl5eV65JFH1Lx5c23evFnz5s3T999/rxUrVti337lzpwYOHChvb2+NGTNGsbGxys3N1Ycffqj//d//1eDBgxUdHa2lS5dWG7ulS5eqffv2SkhIqHPdgKkYAEwjIyPDkGSMGTPG3nbhwgWjdevWhsViMWbPnm1vP336tOHv72+kpqba2+bOnWtIMt588017W2VlpZGQkGAEBgYaJSUlhmEYxvvvv29IMp5//nmH4wwcONCQZLz66qv29iFDhhjdunUzzp8/b2+z2WxGv379jI4dO9rb1q5da0gy1q5d+5Pfsby8vFpbdna2Icl4/fXX7W3Tp083JBnvvfdetf42m80wDMNYsmSJIcl48cUXL9nnUnUdOnSo2ndNTU01JBlTpkypVd2ZmZmGxWIxjhw5Ym+78cYbjaZNmzq0/Wc9hmEYU6dONXx9fY0zZ87Y2woLCw0vLy8jIyOj2nGAqw2XpQATevjhh+1/e3p6Kj4+XoZh6KGHHrK3h4SEqFOnTvrXv/5lb/vkk08UGRmp++67z97m7e2txx57TKWlpVq/fr29n5eXlx555BGH4zz66KMOdZw6dUpffPGFRo4cqbNnz6qoqEhFRUX64YcflJSUpO+++07Hjh2r03fz9/e3/11VVaUffvhBHTp0UEhIiLZt22Zf9+677youLq7GM0MWi8XeJywsrFrd/9nHGf85LjXVXVZWpqKiIvXr10+GYeibb76RJJ08eVIbNmzQgw8+qDZt2lyynpSUFFVUVGjlypX2tuXLl+vChQv6zW9+43TdgFkQbgAT+u8fxuDgYPn5+SksLKxa++nTp+2fjxw5oo4dO8rDw/H/NXTp0sW+/uJ/W7ZsqcDAQId+nTp1cvh88OBBGYahp59+WuHh4Q5LRkaGpB/n+NTFuXPnNH36dEVHR8vX11dhYWEKDw/XmTNnVFxcbO+Xm5ur66677if3lZubq06dOsnLy3VX6L28vNS6detq7Xl5eRo1apSaNWumwMBAhYeHa9CgQZJkr/ti0Py5ujt37qzevXtr6dKl9ralS5fqhhtuUIcOHVz1VYBGizk3gAl5enrWqk36cf5MfbHZbJKkyZMnKykpqcY+df0xfvTRR/Xqq69q4sSJSkhIUHBwsCwWi+6991778VzpUmdwrFZrje2+vr7VwqHVatXNN9+sU6dO6YknnlDnzp3VpEkTHTt2TKNGjXKq7pSUFE2YMEHff/+9Kioq9PXXX2v+/Pl13g9gRoQbAHYxMTHauXOnbDabww/0/v377esv/jcrK0ulpaUOZ28OHDjgsL927dpJ+vHSVmJioktqXLlypVJTUx3u9Dp//ny1O7Xat2+v3bt3/+S+2rdvr02bNqmqqkre3t419gkNDZWkavu/eBarNnbt2qVvv/1Wf/vb35SSkmJvX7NmjUO/i+P1c3VL0r333qv09HS9/fbbOnfunLy9vZWcnFzrmgAz47IUALvbbrtN+fn5Wr58ub3twoULmjdvngIDA+2XUW677TZduHBBCxcutPezWq2aN2+ew/5atGihwYMHa/HixTpx4kS14508ebLONXp6elY72zRv3rxqZ1KGDx+uHTt21HjL9MXthw8frqKiohrPeFzsExMTI09PT23YsMFh/Z/+9Kc61fyf+7z498svv+zQLzw8XDfeeKOWLFmivLy8Guu5KCwsTLfeeqvefPNNLV26VL/85S+rXXYErlacuQFgN2bMGC1evFijRo1STk6OYmNjtXLlSm3cuFFz585V06ZNJUlDhw5V//79NWXKFB0+fFhdu3bVe++95zDn5aIFCxZowIAB6tatm0aPHq127dqpoKBA2dnZ+v7777Vjx4461XjHHXfojTfeUHBwsLp27ars7Gx9/vnnat68uUO/3/3ud1q5cqVGjBihBx98UL169dKpU6f0wQcfaNGiRYqLi1NKSopef/11paena/PmzRo4cKDKysr0+eefa+zYsbrzzjsVHBysESNGaN68ebJYLGrfvr0++uijOs0V6ty5s9q3b6/Jkyfr2LFjCgoK0rvvvusw3+miV155RQMGDFDPnj01ZswYtW3bVocPH9bHH3+s7du3O/RNSUnRPffcI0maNWtWncYRMDV33aYFwPUu3gp+8uRJh/bU1FSjSZMm1foPGjTIuPbaax3aCgoKjLS0NCMsLMzw8fExunXr5nC780U//PCD8cADDxhBQUFGcHCw8cADDxjffPNNtdujDcMwcnNzjZSUFCMyMtLw9vY2oqKijDvuuMNYuXKlvU9tbwU/ffq0vb7AwEAjKSnJ2L9/vxETE+NwW/vFGsePH29ERUUZPj4+RuvWrY3U1FSjqKjI3qe8vNyYNm2a0bZtW8Pb29uIjIw07rnnHiM3N9fe5+TJk8bw4cONgIAAIzQ01Pif//kfY/fu3TXeCl7TOBuGYezdu9dITEw0AgMDjbCwMGP06NHGjh07ahyv3bt3G3fddZcREhJi+Pn5GZ06dTKefvrpavusqKgwQkNDjeDgYOPcuXM/OW7A1cRiGPU4mxAAUG8uXLigVq1aaejQofrrX//q7nKAKwZzbgCgkXr//fd18uRJh0nKACTO3ABAI7Np0ybt3LlTs2bNUlhYmMPDCwFw5gYAGp2FCxfqkUceUYsWLfT666+7uxzgisOZGwAAYCqcuQEAAKZCuAEAAKZy1T3Ez2az6fjx42ratOllvfUXAAA0HMMwdPbsWbVq1ara+9v+21UXbo4fP67o6Gh3lwEAAJxw9OhRtW7d+if7XHXh5uLj448ePaqgoCA3VwMAAGqjpKRE0dHR9t/xn3LVhZuLl6KCgoIINwAANDK1mVLChGIAAGAqhBsAAGAqhBsAAGAqV92cm9qyWq2qqqpydxmNkre3tzw9Pd1dBgDgKkW4+S+GYSg/P19nzpxxdymNWkhIiCIjI3mWEACgwRFu/svFYNOiRQsFBATw41xHhmGovLxchYWFkqSWLVu6uSIAwNWGcPMfrFarPdg0b97c3eU0Wv7+/pKkwsJCtWjRgktUAIAGdUVMKF6wYIFiY2Pl5+envn37avPmzZfs+9prr8lisTgsfn5+Lqnj4hybgIAAl+zvanZxDJm3BABoaG4PN8uXL1d6eroyMjK0bds2xcXFKSkpyX5ZoyZBQUE6ceKEfTly5IhLa+JS1OVjDAEA7uL2cPPiiy9q9OjRSktLU9euXbVo0SIFBARoyZIll9zGYrEoMjLSvkRERDRgxQAA4Erm1nBTWVmpnJwcJSYm2ts8PDyUmJio7OzsS25XWlqqmJgYRUdH684779SePXsu2beiokIlJSUOC35abGys5s6d6+4yAABwilvDTVFRkaxWa7UzLxEREcrPz69xm06dOmnJkiX6+9//rjfffFM2m039+vXT999/X2P/zMxMBQcH2xezvhF88ODBmjhxokv2tWXLFo0ZM8Yl+wIAoKE1urulEhISlJCQYP/cr18/denSRYsXL9asWbOq9Z86darS09Ptny++VdTVDMOQzXD5bmt//P9fg/USRRiGIavVKi+vn/+fvFnzMEm65L5qw2ozZDMMnau8IJvHBaf3AwBonPy9Pd02/9Kt4SYsLEyenp4qKChwaC8oKFBkZGSt9uHt7a3rr79eBw8erHG9r6+vfH19L7vWn2MzpD3Hi+v9ODV5etJYbVi/XhvWr9crr7wiSZo5Z4GmPz5OC15/R/P/+L/6bv9eLVr6niJbRumFmdO085utOldernYdrtFjU6brhoGD7fu7NaG77n/oEf3m4UckSXHRocp4/mVtyPpM2eu/UIvIlnr86VkafMttl6zJuFCpwjPnNWbVlzp21lqv3x8AcOXZOzNJAT7uiRluvSzl4+OjXr16KSsry95ms9mUlZXlcHbmp1itVu3ataveHhZnGIbKKy/UajlfZXXpYhi1O3Py+2cyFdert4b/OlVZOfuVlbNfka2iJEkvZz6jCVMy9P4Xm3RN52tVXl6qATfdrD+//b6Wr16vfoOH6LG0+3Ti2NGfPMail55T0h3DtOKzLzXgpps19bH/UfHp05c9vgAAuJrbL0ulp6crNTVV8fHx6tOnj+bOnauysjKlpaVJklJSUhQVFaXMzExJ0syZM3XDDTeoQ4cOOnPmjP74xz/qyJEjevjhh+ulvnNVVnWd/mm97Pvn7JpxS+1Sb6tgBQcGKCosWIN6XCNJMs4clyTN/t8/6Fd33vnvvtfG6u7EAfaPt/Xvqa+y/qEDm9cpcdx4SZK3p4cig/10batge7+HHkzT5LEPSZJu7PGC3lqyWCVH96vftb+ssaTz58/Lq9xPHz06QL4ueg4RAKDx8Pd23wNc3R5ukpOTdfLkSU2fPl35+fnq0aOHVq9ebZ9knJeXJw+Pf59gOn36tEaPHq38/HyFhoaqV69e+uqrr9S1a1d3fYV64+lhkadH7a5XWvTjLfIX+1/8b58+vR32UVpaqhkzZujjjz/WiRMndOHCBZ07d07fHz3q0M/D4njsHnFx9s9BTQMVFBSkH4pOXrI+Tw+LPCwW+ft4yc9NpyUBAFenK+JXZ/z48Ro/fnyN69atW+fw+aWXXtJLL73UAFX9yN/bU3tnJjXY8f772JerSZMmDp8nT56sNWvW6IUXXlCHDh3k7++ve+65R5WVlT+5H29vb4fPFotFNpvtsusDAMDVrohwcyWzWCxumxBVFz4+PrJaf37i7saNGzVq1Cjdddddkn48k3P48OF6rg4AgIbj9icUwzViY2O1adMmHT58WEVFRZc8q9KxY0e999572r59u3bs2KFf//rXnIEBAJgK4cYkJk+eLE9PT3Xt2lXh4eHKy8ursd+LL76o0NBQ9evXT0OHDlVSUpJ69uzZwNUCAFB/LEZt7zc2iZKSEgUHB6u4uFhBQUEO686fP69Dhw6pbdu2LnvT+NWKsQQAuNJP/X7/N87cAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcmMTgwYM1ceJEl+1v1KhRGjZsmMv2BwBAQyHcAAAAUyHcmMCoUaO0fv16vfzyy7JYLLJYLDp8+LB2796tW2+9VYGBgYqIiNADDzygoqIi+3YrV65Ut27d5O/vr+bNmysxMVFlZWWaMWOG/va3v+nvf/+7fX/r1q1z3xcEAKAOvNxdwBXPMKSqcvcc2ztAslh+ttvLL7+sb7/9Vtddd51mzpz546be3urTp48efvhhvfTSSzp37pyeeOIJjRw5Ul988YVOnDih++67T88//7zuuusunT17Vv/85z9lGIYmT56sffv2qaSkRK+++qokqVmzZvX6VQEAcBXCzc+pKpeebeWeYz95XPJp8rPdgoOD5ePjo4CAAEVGRkqS/vCHP+j666/Xs88+a++3ZMkSRUdH69tvv1VpaakuXLigu+++WzExMZKkbt262fv6+/uroqLCvj8AABoLwo1J7dixQ2vXrlVgYGC1dbm5ubrllls0ZMgQdevWTUlJSbrlllt0zz33KDQ01A3VAgDgOoSbn+Md8OMZFHcd20mlpaUaOnSonnvuuWrrWrZsKU9PT61Zs0ZfffWVPvvsM82bN0/Tpk3Tpk2b1LZt28upGgAAtyLc/ByLpVaXhtzNx8dHVqvV/rlnz5569913FRsbKy+vmv9ntlgs6t+/v/r376/p06crJiZGq1atUnp6erX9AQDQWHC3lEnExsZq06ZNOnz4sIqKijRu3DidOnVK9913n7Zs2aLc3Fx9+umnSktLk9Vq1aZNm/Tss89q69atysvL03vvvaeTJ0+qS5cu9v3t3LlTBw4cUFFRkaqqqtz8DQEAqB3CjUlMnjxZnp6e6tq1q8LDw1VZWamNGzfKarXqlltuUbdu3TRx4kSFhITIw8NDQUFB2rBhg2677TZdc801euqppzRnzhzdeuutkqTRo0erU6dOio+PV3h4uDZu3OjmbwgAQO1YDMMw3F1EQyopKVFwcLCKi4sVFBTksO78+fM6dOiQ2rZtKz8/PzdVaA6MJQDAlX7q9/u/ceYGAACYCuEGAACYCuEGAACYCuEGAACYCuGmBlfZHOt6wRgCANyFcPMfvL29JUnl5W56UaaJXBzDi2MKAEBD4QnF/8HT01MhISEqLCyUJAUEBMhSi7dy498Mw1B5ebkKCwsVEhIiT09Pd5cEALjKEG7+y8W3YF8MOHBOSEgIbxQHALgF4ea/WCwWtWzZUi1atOCVA07y9vbmjA0AwG0IN5fg6enJDzQAAI0QE4oBAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpXBHhZsGCBYqNjZWfn5/69u2rzZs312q7ZcuWyWKxaNiwYfVbIAAAaDTcHm6WL1+u9PR0ZWRkaNu2bYqLi1NSUpIKCwt/crvDhw9r8uTJGjhwYANVCgAAGgO3h5sXX3xRo0ePVlpamrp27apFixYpICBAS5YsueQ2VqtV999/v5555hm1a9euAasFAABXOreGm8rKSuXk5CgxMdHe5uHhocTERGVnZ19yu5kzZ6pFixZ66KGHfvYYFRUVKikpcVgAAIB5uTXcFBUVyWq1KiIiwqE9IiJC+fn5NW7z5Zdf6q9//av+8pe/1OoYmZmZCg4Oti/R0dGXXTcAALhyuf2yVF2cPXtWDzzwgP7yl78oLCysVttMnTpVxcXF9uXo0aP1XCUAAHAnL3cePCwsTJ6eniooKHBoLygoUGRkZLX+ubm5Onz4sIYOHWpvs9lskiQvLy8dOHBA7du3d9jG19dXvr6+9VA9AAC4Ern1zI2Pj4969eqlrKwse5vNZlNWVpYSEhKq9e/cubN27dql7du325df/epX+sUvfqHt27dzyQkAALj3zI0kpaenKzU1VfHx8erTp4/mzp2rsrIypaWlSZJSUlIUFRWlzMxM+fn56brrrnPYPiQkRJKqtQMAgKuT28NNcnKyTp48qenTpys/P189evTQ6tWr7ZOM8/Ly5OHRqKYGAQAAN7IYhmG4u4iGVFJSouDgYBUXFysoKMjd5QAAgFqoy+83p0QAAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpXBHhZsGCBYqNjZWfn5/69u2rzZs3X7Lve++9p/j4eIWEhKhJkybq0aOH3njjjQasFgAAXMncHm6WL1+u9PR0ZWRkaNu2bYqLi1NSUpIKCwtr7N+sWTNNmzZN2dnZ2rlzp9LS0pSWlqZPP/20gSsHAABXIothGIY7C+jbt6969+6t+fPnS5JsNpuio6P16KOPasqUKbXaR8+ePXX77bdr1qxZP9u3pKREwcHBKi4uVlBQ0GXVDgAAGkZdfr/deuamsrJSOTk5SkxMtLd5eHgoMTFR2dnZP7u9YRjKysrSgQMHdOONN9ZnqQAAoJHwcufBi4qKZLVaFRER4dAeERGh/fv3X3K74uJiRUVFqaKiQp6envrTn/6km2++uca+FRUVqqiosH8uKSlxTfEAAOCK5NZw46ymTZtq+/btKi0tVVZWltLT09WuXTsNHjy4Wt/MzEw988wzDV8kAABwC7eGm7CwMHl6eqqgoMChvaCgQJGRkZfczsPDQx06dJAk9ejRQ/v27VNmZmaN4Wbq1KlKT0+3fy4pKVF0dLRrvgAAALjiuHXOjY+Pj3r16qWsrCx7m81mU1ZWlhISEmq9H5vN5nDp6T/5+voqKCjIYQEAAObl9stS6enpSk1NVXx8vPr06aO5c+eqrKxMaWlpkqSUlBRFRUUpMzNT0o+XmeLj49W+fXtVVFTok08+0RtvvKGFCxe682sAAIArhNvDTXJysk6ePKnp06crPz9fPXr00OrVq+2TjPPy8uTh8e8TTGVlZRo7dqy+//57+fv7q3PnznrzzTeVnJzsrq8AAACuIG5/zk1D4zk3AAA0PvX+nJu1a9c6VRgAAEB9cyrc/PKXv1T79u31hz/8QUePHnV1TQAAAE5zKtwcO3ZM48eP18qVK9WuXTslJSXpnXfeUWVlpavrAwAAqBOnwk1YWJgmTZqk7du3a9OmTbrmmms0duxYtWrVSo899ph27Njh6joBAABq5bKfc9OzZ09NnTpV48ePV2lpqZYsWaJevXpp4MCB2rNnjytqBAAAqDWnw01VVZVWrlyp2267TTExMfr00081f/58FRQU6ODBg4qJidGIESNcWSsAAMDPcupW8EcffVRvv/22DMPQAw88oIcffljXXXedQ5/8/Hy1atVKNpvNZcW6AreCAwDQ+NTl99uph/jt3btX8+bN09133y1fX98a+4SFhXHLOAAAaHA8xA8AAFzx6v0hfpmZmVqyZEm19iVLlui5555zZpcAAAAu4VS4Wbx4sTp37lyt/dprr9WiRYsuuygAAABnORVu8vPz1bJly2rt4eHhOnHixGUXBQAA4Cynwk10dLQ2btxYrX3jxo1q1arVZRcFAADgLKfulho9erQmTpyoqqoq3XTTTZKkrKws/f73v9fjjz/u0gIBAADqwqlw87vf/U4//PCDxo4da3+flJ+fn5544glNnTrVpQUCAADUxWXdCl5aWqp9+/bJ399fHTt2vOQzb64k3AoOAEDjU+8P8bsoMDBQvXv3vpxdAAAAuJTT4Wbr1q165513lJeXZ780ddF777132YUBAAA4w6m7pZYtW6Z+/fpp3759WrVqlaqqqrRnzx598cUXCg4OdnWNAAAAteZUuHn22Wf10ksv6cMPP5SPj49efvll7d+/XyNHjlSbNm1cXSMAAECtORVucnNzdfvtt0uSfHx8VFZWJovFokmTJunPf/6zSwsEAACoC6fCTWhoqM6ePStJioqK0u7duyVJZ86cUXl5ueuqAwAAqCOnJhTfeOONWrNmjbp166YRI0ZowoQJ+uKLL7RmzRoNGTLE1TUCAADUmlPhZv78+Tp//rwkadq0afL29tZXX32l4cOH66mnnnJpgQAAAHVR53Bz4cIFffTRR0pKSpIkeXh4aMqUKS4vDAAAwBl1nnPj5eWl3/72t/YzNwAAAFcSpyYU9+nTR9u3b3dxKQAAAJfPqTk3Y8eOVXp6uo4ePapevXqpSZMmDuu7d+/ukuIAAADqyqkXZ3p4VD/hY7FYZBiGLBaLrFarS4qrD7w4EwCAxqfeX5x56NAhpwoDAACob06Fm5iYGFfXAQAA4BJOhZvXX3/9J9enpKQ4VQwAAMDlcmrOTWhoqMPnqqoqlZeXy8fHRwEBATp16pTLCnQ15twAAND41OX326lbwU+fPu2wlJaW6sCBAxowYIDefvttp4oGAABwBafCTU06duyo2bNna8KECa7aJQAAQJ25LNxIPz69+Pjx467cJQAAQJ04NaH4gw8+cPhsGIZOnDih+fPnq3///i4pDAAAwBlOhZthw4Y5fLZYLAoPD9dNN92kOXPmuKIuAAAApzgVbmw2m6vrAAAAcAmXzrkBAABwN6fCzfDhw/Xcc89Va3/++ec1YsSIyy4KAADAWU6Fmw0bNui2226r1n7rrbdqw4YNl10UAACAs5wKN6WlpfLx8anW7u3trZKSkssuCgAAwFlOhZtu3bpp+fLl1dqXLVumrl27XnZRAAAAznLqbqmnn35ad999t3Jzc3XTTTdJkrKysvT2229rxYoVLi0QAACgLpwKN0OHDtX777+vZ599VitXrpS/v7+6d++uzz//XIMGDXJ1jQAAALXm1FvBGzPeCg4AQONT728F37JlizZt2lStfdOmTdq6daszuwQAAHAJp8LNuHHjdPTo0Wrtx44d07hx4y67KAAAAGc5FW727t2rnj17Vmu//vrrtXfv3ssuCgAAwFlOhRtfX18VFBRUaz9x4oS8vJyaowwAAOASToWbW265RVOnTlVxcbG97cyZM3ryySd18803u6w4AACAunLqNMsLL7ygG2+8UTExMbr++uslSdu3b1dERITeeOMNlxYIAABQF06Fm6ioKO3cuVNLly7Vjh075O/vr7S0NN13333y9vZ2dY0AAAC15vQEmSZNmmjAgAFq06aNKisrJUn/+Mc/JEm/+tWvXFMdAABAHTkVbv71r3/prrvu0q5du2SxWGQYhiwWi3291Wp1WYEAAAB14dSE4gkTJqht27YqLCxUQECAdu/erfXr1ys+Pl7r1q1zcYkAAAC151S4yc7O1syZMxUWFiYPDw95enpqwIAByszM1GOPPVbn/S1YsECxsbHy8/NT3759tXnz5kv2/ctf/qKBAwcqNDRUoaGhSkxM/Mn+AADg6uJUuLFarWratKkkKSwsTMePH5ckxcTE6MCBA3Xa1/Lly5Wenq6MjAxt27ZNcXFxSkpKUmFhYY39161bp/vuu09r165Vdna2oqOjdcstt+jYsWPOfBUAAGAyTr04c+DAgXr88cc1bNgw/frXv9bp06f11FNP6c9//rNycnK0e/fuWu+rb9++6t27t+bPny9Jstlsio6O1qOPPqopU6b87PZWq1WhoaGaP3++UlJSfrY/L84EAKDxqcvvt1MTip966imVlZVJkmbOnKk77rhDAwcOVPPmzbV8+fJa76eyslI5OTmaOnWqvc3Dw0OJiYnKzs6u1T7Ky8tVVVWlZs2a1bi+oqJCFRUV9s8lJSW1rg8AADQ+ToWbpKQk+98dOnTQ/v37derUKYWGhjrcNfVzioqKZLVaFRER4dAeERGh/fv312ofTzzxhFq1aqXExMQa12dmZuqZZ56pdU0AAKBxc2rOTU2aNWtWp2DjCrNnz9ayZcu0atUq+fn51djn4msiLi41vc0cAACYh1vfchkWFiZPT89qL+EsKChQZGTkT277wgsvaPbs2fr888/VvXv3S/bz9fWVr6+vS+oFAABXPpeduXGGj4+PevXqpaysLHubzWZTVlaWEhISLrnd888/r1mzZmn16tWKj49viFIBAEAj4dYzN5KUnp6u1NRUxcfHq0+fPpo7d67KysqUlpYmSUpJSVFUVJQyMzMlSc8995ymT5+ut956S7GxscrPz5ckBQYGKjAw0G3fAwAAXBncHm6Sk5N18uRJTZ8+Xfn5+erRo4dWr15tn2Scl5cnD49/n2BauHChKisrdc899zjsJyMjQzNmzGjI0gEAwBXIqefcNGY85wYAgManLr/fbp1zAwAA4GqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCpuDzcLFixQbGys/Pz81LdvX23evPmSfffs2aPhw4crNjZWFotFc+fObbhCAQBAo+DWcLN8+XKlp6crIyND27ZtU1xcnJKSklRYWFhj//LycrVr106zZ89WZGRkA1cLAAAaA7eGmxdffFGjR49WWlqaunbtqkWLFikgIEBLliypsX/v3r31xz/+Uffee698fX0buFoAANAYuC3cVFZWKicnR4mJif8uxsNDiYmJys7OdtlxKioqVFJS4rAAAADzclu4KSoqktVqVUREhEN7RESE8vPzXXaczMxMBQcH25fo6GiX7RsAAFx53D6huL5NnTpVxcXF9uXo0aPuLgkAANQjL3cdOCwsTJ6eniooKHBoLygocOlkYV9fX+bnAABwFXHbmRsfHx/16tVLWVlZ9jabzaasrCwlJCS4qywAANDIue3MjSSlp6crNTVV8fHx6tOnj+bOnauysjKlpaVJklJSUhQVFaXMzExJP05C3rt3r/3vY8eOafv27QoMDFSHDh3c9j0AAMCVw63hJjk5WSdPntT06dOVn5+vHj16aPXq1fZJxnl5efLw+PfJpePHj+v666+3f37hhRf0wgsvaNCgQVq3bl1Dlw8AAK5AFsMwDHcX0ZBKSkoUHBys4uJiBQUFubscAABQC3X5/Tb93VIAAODqQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmckWEmwULFig2NlZ+fn7q27evNm/e/JP9V6xYoc6dO8vPz0/dunXTJ5980kCVAgCAK53bw83y5cuVnp6ujIwMbdu2TXFxcUpKSlJhYWGN/b/66ivdd999euihh/TNN99o2LBhGjZsmHbv3t3AlQMAgCuRxTAMw50F9O3bV71799b8+fMlSTabTdHR0Xr00Uc1ZcqUav2Tk5NVVlamjz76yN52ww03qEePHlq0aNHPHq+kpETBwcEqLi5WUFCQ676IYUhV5a7bHwAAjZl3gGSxuGx3dfn99nLZUZ1QWVmpnJwcTZ061d7m4eGhxMREZWdn17hNdna20tPTHdqSkpL0/vvv19i/oqJCFRUV9s8lJSWXX3hNqsqlZ1vVz74BAGhsnjwu+TRxy6HdelmqqKhIVqtVERERDu0RERHKz8+vcZv8/Pw69c/MzFRwcLB9iY6Odk3xAADgiuTWMzcNYerUqQ5nekpKSuon4HgH/JhSAQDAj7+LbuLWcBMWFiZPT08VFBQ4tBcUFCgyMrLGbSIjI+vU39fXV76+vq4p+KdYLG47/QYAAP7NrZelfHx81KtXL2VlZdnbbDabsrKylJCQUOM2CQkJDv0lac2aNZfsDwAAri5uvyyVnp6u1NRUxcfHq0+fPpo7d67KysqUlpYmSUpJSVFUVJQyMzMlSRMmTNCgQYM0Z84c3X777Vq2bJm2bt2qP//5z+78GgAA4Arh9nCTnJyskydPavr06crPz1ePHj20evVq+6ThvLw8eXj8+wRTv3799NZbb+mpp57Sk08+qY4dO+r999/Xdddd566vAAAAriBuf85NQ6u359wAAIB6U5ffb7c/oRgAAMCVCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBU3P76hYZ28YHMJSUlbq4EAADU1sXf7dq8WOGqCzdnz56VJEVHR7u5EgAAUFdnz55VcHDwT/a56t4tZbPZdPz4cTVt2lQWi8Wl+y4pKVF0dLSOHj3Ke6saAOPdsBjvhsV4NyzGu2E5M96GYejs2bNq1aqVwwu1a3LVnbnx8PBQ69at6/UYQUFB/B9HA2K8Gxbj3bAY74bFeDesuo73z52xuYgJxQAAwFQINwAAwFQINy7k6+urjIwM+fr6uruUqwLj3bAY74bFeDcsxrth1fd4X3UTigEAgLlx5gYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4cZFFixYoNjYWPn5+alv377avHmzu0syjQ0bNmjo0KFq1aqVLBaL3n//fYf1hmFo+vTpatmypfz9/ZWYmKjvvvvOPcU2cpmZmerdu7eaNm2qFi1aaNiwYTpw4IBDn/Pnz2vcuHFq3ry5AgMDNXz4cBUUFLip4sZt4cKF6t69u/1BZgkJCfrHP/5hX89Y16/Zs2fLYrFo4sSJ9jbG3HVmzJghi8XisHTu3Nm+vj7HmnDjAsuXL1d6eroyMjK0bds2xcXFKSkpSYWFhe4uzRTKysoUFxenBQsW1Lj++eef1yuvvKJFixZp06ZNatKkiZKSknT+/PkGrrTxW79+vcaNG6evv/5aa9asUVVVlW655RaVlZXZ+0yaNEkffvihVqxYofXr1+v48eO6++673Vh149W6dWvNnj1bOTk52rp1q2666Sbdeeed2rNnjyTGuj5t2bJFixcvVvfu3R3aGXPXuvbaa3XixAn78uWXX9rX1etYG7hsffr0McaNG2f/bLVajVatWhmZmZlurMqcJBmrVq2yf7bZbEZkZKTxxz/+0d525swZw9fX13j77bfdUKG5FBYWGpKM9evXG4bx49h6e3sbK1assPfZt2+fIcnIzs52V5mmEhoaavzf//0fY12Pzp49a3Ts2NFYs2aNMWjQIGPChAmGYfDv29UyMjKMuLi4GtfV91hz5uYyVVZWKicnR4mJifY2Dw8PJSYmKjs7242VXR0OHTqk/Px8h/EPDg5W3759GX8XKC4uliQ1a9ZMkpSTk6OqqiqH8e7cubPatGnDeF8mq9WqZcuWqaysTAkJCYx1PRo3bpxuv/12h7GV+PddH7777ju1atVK7dq10/3336+8vDxJ9T/WV92LM12tqKhIVqtVERERDu0RERHav3+/m6q6euTn50tSjeN/cR2cY7PZNHHiRPXv31/XXXedpB/H28fHRyEhIQ59GW/n7dq1SwkJCTp//rwCAwO1atUqde3aVdu3b2es68GyZcu0bds2bdmypdo6/n27Vt++ffXaa6+pU6dOOnHihJ555hkNHDhQu3fvrvexJtwAqNG4ceO0e/duh2vkcL1OnTpp+/btKi4u1sqVK5Wamqr169e7uyxTOnr0qCZMmKA1a9bIz8/P3eWY3q233mr/u3v37urbt69iYmL0zjvvyN/fv16PzWWpyxQWFiZPT89qM7wLCgoUGRnppqquHhfHmPF3rfHjx+ujjz7S2rVr1bp1a3t7ZGSkKisrdebMGYf+jLfzfHx81KFDB/Xq1UuZmZmKi4vTyy+/zFjXg5ycHBUWFqpnz57y8vKSl5eX1q9fr1deeUVeXl6KiIhgzOtRSEiIrrnmGh08eLDe/30Tbi6Tj4+PevXqpaysLHubzWZTVlaWEhIS3FjZ1aFt27aKjIx0GP+SkhJt2rSJ8XeCYRgaP368Vq1apS+++EJt27Z1WN+rVy95e3s7jPeBAweUl5fHeLuIzWZTRUUFY10PhgwZol27dmn79u32JT4+Xvfff7/9b8a8/pSWlio3N1ctW7as/3/flz0lGcayZcsMX19f47XXXjP27t1rjBkzxggJCTHy8/PdXZopnD171vjmm2+Mb775xpBkvPjii8Y333xjHDlyxDAMw5g9e7YREhJi/P3vfzd27txp3HnnnUbbtm2Nc+fOubnyxueRRx4xgoODjXXr1hknTpywL+Xl5fY+v/3tb402bdoYX3zxhbF161YjISHBSEhIcGPVjdeUKVOM9evXG4cOHTJ27txpTJkyxbBYLMZnn31mGAZj3RD+824pw2DMXenxxx831q1bZxw6dMjYuHGjkZiYaISFhRmFhYWGYdTvWBNuXGTevHlGmzZtDB8fH6NPnz7G119/7e6STGPt2rWGpGpLamqqYRg/3g7+9NNPGxEREYavr68xZMgQ48CBA+4tupGqaZwlGa+++qq9z7lz54yxY8caoaGhRkBAgHHXXXcZJ06ccF/RjdiDDz5oxMTEGD4+PkZ4eLgxZMgQe7AxDMa6Ifx3uGHMXSc5Odlo2bKl4ePjY0RFRRnJycnGwYMH7evrc6wthmEYl3/+BwAA4MrAnBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAV71169bJYrFUe88NgMaJcAMAAEyFcAMAAEyFcAPA7Ww2mzIzM9W2bVv5+/srLi5OK1eulPTvS0Yff/yxunfvLj8/P91www3avXu3wz7effddXXvttfL19VVsbKzmzJnjsL6iokJPPPGEoqOj5evrqw4dOuivf/2rQ5+cnBzFx8crICBA/fr104EDB+r3iwOoF4QbAG6XmZmp119/XYsWLdKePXs0adIk/eY3v9H69evtfX73u99pzpw52rJli8LDwzV06FBVVVVJ+jGUjBw5Uvfee6927dqlGTNm6Omnn9Zrr71m3z4lJUVvv/22XnnlFe3bt0+LFy9WYGCgQx3Tpk3TnDlztHXrVnl5eenBBx9skO8PwLV4cSYAt6qoqFCzZs30+eefKyEhwd7+8MMPq7y8XGPGjNEvfvELLVu2TMnJyZKkU6dOqXXr1nrttdc0cuRI3X///Tp58qQ+++wz+/a///3v9fHHH2vPnj369ttv1alTJ61Zs0aJiYnVali3bp1+8Ytf6PPPP9eQIUMkSZ988oluv/12nTt3Tn5+fvU8CgBciTM3ANzq4MGDKi8v180336zAwED78vrrrys3N9fe7z+DT7NmzdSpUyft27dPkrRv3z7179/fYb/9+/fXd999J6vVqu3bt8vT01ODBg36yVq6d+9u/7tly5aSpMLCwsv+jgAalpe7CwBwdSstLZUkffzxx4qKinJY5+vr6xBwnOXv71+rft7e3va/LRaLpB/nAwFoXDhzA8CtunbtKl9fX+Xl5alDhw4OS3R0tL3f119/bf/79OnT+vbbb9WlSxdJUpcuXbRx40aH/W7cuFHXXHONPD091a1bN9lsNoc5PADMizM3ANyqadOmmjx5siZNmiSbzaYBAwaouLhYGzduVFBQkGJiYiRJM2fOVPPmzRUREaFp06YpLCxMw4YNkyQ9/vjj6t27t2bNmqXk5GRlZ2dr/vz5+tOf/iRJio2NVWpqqh588EG98soriouL05EjR1RYWKiRI0e666sDqCeEGwBuN2vWLIWHhyszM1P/+te/FBISop49e+rJJ5+0XxaaPXu2JkyYoO+++049evTQhx9+KB8fH0lSz5499c4772j69OmaNWuWWrZsqZkzZ2rUqFH2YyxcuFBPPvmkxo4dqx9++EFt2rTRk08+6Y6vC6CecbcUgCvaxTuZTp8+rZCQEHeXA6ARYM4NAAAwFcINAAAwFS5LAQAAU+HMDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMJX/BxorJ7q+BHMnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show the application of Dropout Regularization"
      ],
      "metadata": {
        "id": "J4Xfqnl30_QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = keras.Sequential([\n",
        "    Dense(64, input_shape=input_shape, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "xyWRXzjf1IVo"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "StorlN4K16fI",
        "outputId": "83c0b6b9-d774-4448-90fc-4ae471c06511"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/5 [=====>........................] - ETA: 26s - loss: 0.0000e+00 - accuracy: 0.3125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 9s 539ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3169 - val_loss: 0.0000e+00 - val_accuracy: 0.3889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training (Dropout)')\n",
        "plt.plot(history.history['val_loss'], label='Validation (Dropout)')\n",
        "plt.plot(history.history['loss'], label='Training (No Dropout)')\n",
        "plt.plot(history.history['val_loss'], label='Validation (No Dropout)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "9w-6TldJ3iT9",
        "outputId": "8dbc1270-7bf7-4feb-8ab1-dfedc85647e0"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the application of Dropout on the visible layer\n",
        "# Show the application of Dropout on the hidden layer"
      ],
      "metadata": {
        "id": "knLtcPfM5oS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    #Visible Layer\n",
        "    keras.layers.Input(shape=(input_shape)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    #Hidden Layer\n",
        "    keras.layers.Dense(units=32, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),  #\n",
        "    keras.layers.Dense(units=16, activation='relu'),\n",
        "])"
      ],
      "metadata": {
        "id": "qEqqLorb4rME"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show the application of a time-based learning rate schedule"
      ],
      "metadata": {
        "id": "PaOlCjuT6B9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "dropout_rate1 = 0.5\n",
        "dropout_rate2 = 0.3\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.33, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(dropout_rate1))  # Apply dropout with defined rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(dropout_rate2))  # Apply dropout with defined rate\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "learning_rate = 0.0001\n",
        "momentum = 0.8\n",
        "sgd = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "epochs = 150\n",
        "batch_size = 28\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5oMmiFri6ETB",
        "outputId": "f6251e3d-282b-4f4c-e346-116ad979801b"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "5/5 [==============================] - 1s 68ms/step - loss: 33.8011 - accuracy: 0.3613 - val_loss: 13.1588 - val_accuracy: 0.4068\n",
            "Epoch 2/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 26.7434 - accuracy: 0.3866 - val_loss: 3.0366 - val_accuracy: 0.4068\n",
            "Epoch 3/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 14.6187 - accuracy: 0.3950 - val_loss: 5.7253 - val_accuracy: 0.4068\n",
            "Epoch 4/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.1348 - accuracy: 0.4202 - val_loss: 8.2578 - val_accuracy: 0.4068\n",
            "Epoch 5/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 10.0453 - accuracy: 0.3697 - val_loss: 2.8857 - val_accuracy: 0.4068\n",
            "Epoch 6/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.1798 - accuracy: 0.3866 - val_loss: 0.9517 - val_accuracy: 0.4746\n",
            "Epoch 7/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 9.8431 - accuracy: 0.3866 - val_loss: 0.7867 - val_accuracy: 0.4068\n",
            "Epoch 8/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.4036 - accuracy: 0.3866 - val_loss: 2.0785 - val_accuracy: 0.4068\n",
            "Epoch 9/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.5421 - accuracy: 0.3866 - val_loss: 1.5087 - val_accuracy: 0.4068\n",
            "Epoch 10/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7735 - accuracy: 0.3782 - val_loss: 0.7394 - val_accuracy: 0.4068\n",
            "Epoch 11/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.2030 - accuracy: 0.3277 - val_loss: 0.8299 - val_accuracy: 0.4407\n",
            "Epoch 12/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0073 - accuracy: 0.4034 - val_loss: 0.4904 - val_accuracy: 0.4068\n",
            "Epoch 13/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9996 - accuracy: 0.4118 - val_loss: 0.6903 - val_accuracy: 0.4068\n",
            "Epoch 14/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3358 - accuracy: 0.4118 - val_loss: 0.5786 - val_accuracy: 0.4068\n",
            "Epoch 15/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2377 - accuracy: 0.3950 - val_loss: 0.5854 - val_accuracy: 0.4068\n",
            "Epoch 16/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4272 - accuracy: 0.4202 - val_loss: 0.5917 - val_accuracy: 0.4068\n",
            "Epoch 17/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6605 - accuracy: 0.4370 - val_loss: 0.6019 - val_accuracy: 0.4068\n",
            "Epoch 18/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9422 - accuracy: 0.4118 - val_loss: 0.5726 - val_accuracy: 0.4068\n",
            "Epoch 19/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2550 - accuracy: 0.4202 - val_loss: 0.4883 - val_accuracy: 0.4068\n",
            "Epoch 20/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2064 - accuracy: 0.4118 - val_loss: 0.5143 - val_accuracy: 0.4068\n",
            "Epoch 21/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9735 - accuracy: 0.4286 - val_loss: 0.5307 - val_accuracy: 0.4068\n",
            "Epoch 22/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5511 - accuracy: 0.3866 - val_loss: 0.5252 - val_accuracy: 0.4068\n",
            "Epoch 23/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7834 - accuracy: 0.4454 - val_loss: 0.5084 - val_accuracy: 0.4068\n",
            "Epoch 24/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9940 - accuracy: 0.4118 - val_loss: 0.4592 - val_accuracy: 0.4068\n",
            "Epoch 25/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9286 - accuracy: 0.4538 - val_loss: 0.4806 - val_accuracy: 0.4576\n",
            "Epoch 26/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0582 - accuracy: 0.3866 - val_loss: 0.4764 - val_accuracy: 0.6441\n",
            "Epoch 27/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8745 - accuracy: 0.3950 - val_loss: 0.5008 - val_accuracy: 0.7288\n",
            "Epoch 28/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1259 - accuracy: 0.4118 - val_loss: 0.3874 - val_accuracy: 0.4068\n",
            "Epoch 29/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5371 - accuracy: 0.3866 - val_loss: 0.4821 - val_accuracy: 0.4068\n",
            "Epoch 30/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8868 - accuracy: 0.3277 - val_loss: 0.5978 - val_accuracy: 0.4068\n",
            "Epoch 31/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9234 - accuracy: 0.4286 - val_loss: 0.5814 - val_accuracy: 0.4068\n",
            "Epoch 32/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5813 - accuracy: 0.4034 - val_loss: 0.4523 - val_accuracy: 0.4068\n",
            "Epoch 33/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8794 - accuracy: 0.4286 - val_loss: 0.0293 - val_accuracy: 0.4068\n",
            "Epoch 34/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -0.4334 - accuracy: 0.4202 - val_loss: -0.4357 - val_accuracy: 0.4068\n",
            "Epoch 35/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.1940 - accuracy: 0.4790 - val_loss: -0.1179 - val_accuracy: 0.6949\n",
            "Epoch 36/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -0.4652 - accuracy: 0.4202 - val_loss: -0.4653 - val_accuracy: 0.6441\n",
            "Epoch 37/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0827 - accuracy: 0.4454 - val_loss: -0.6484 - val_accuracy: 0.6441\n",
            "Epoch 38/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.3068 - accuracy: 0.4622 - val_loss: 0.1730 - val_accuracy: 0.6441\n",
            "Epoch 39/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5869 - accuracy: 0.4790 - val_loss: 0.6242 - val_accuracy: 0.4915\n",
            "Epoch 40/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6887 - accuracy: 0.4202 - val_loss: 0.5045 - val_accuracy: 0.5254\n",
            "Epoch 41/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.4118 - val_loss: -0.8284 - val_accuracy: 0.4068\n",
            "Epoch 42/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -0.2086 - accuracy: 0.4370 - val_loss: -0.7415 - val_accuracy: 0.4068\n",
            "Epoch 43/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -0.0685 - accuracy: 0.3950 - val_loss: -0.6696 - val_accuracy: 0.5593\n",
            "Epoch 44/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.5453 - accuracy: 0.4286 - val_loss: -0.8155 - val_accuracy: 0.4068\n",
            "Epoch 45/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7567 - accuracy: 0.4202 - val_loss: 0.1339 - val_accuracy: 0.6441\n",
            "Epoch 46/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1896 - accuracy: 0.5462 - val_loss: 0.5075 - val_accuracy: 0.5593\n",
            "Epoch 47/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.4202 - val_loss: -0.0712 - val_accuracy: 0.4068\n",
            "Epoch 48/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.0387 - accuracy: 0.3697 - val_loss: -0.6205 - val_accuracy: 0.4407\n",
            "Epoch 49/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4353 - accuracy: 0.4034 - val_loss: -0.6918 - val_accuracy: 0.5593\n",
            "Epoch 50/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7634 - accuracy: 0.4454 - val_loss: 0.3738 - val_accuracy: 0.4068\n",
            "Epoch 51/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4505 - accuracy: 0.4454 - val_loss: 0.3060 - val_accuracy: 0.6102\n",
            "Epoch 52/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1846 - accuracy: 0.4958 - val_loss: -0.5195 - val_accuracy: 0.6949\n",
            "Epoch 53/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: -1.8351 - accuracy: 0.4790 - val_loss: 0.9038 - val_accuracy: 0.4068\n",
            "Epoch 54/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.9490 - accuracy: 0.4202 - val_loss: -0.9663 - val_accuracy: 0.6441\n",
            "Epoch 55/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5940 - accuracy: 0.4706 - val_loss: -0.8800 - val_accuracy: 0.5593\n",
            "Epoch 56/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: -0.0859 - accuracy: 0.4286 - val_loss: -0.4732 - val_accuracy: 0.6441\n",
            "Epoch 57/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -0.1065 - accuracy: 0.4454 - val_loss: -0.2229 - val_accuracy: 0.6949\n",
            "Epoch 58/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2499 - accuracy: 0.5546 - val_loss: -0.0882 - val_accuracy: 0.4746\n",
            "Epoch 59/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: -0.1128 - accuracy: 0.4454 - val_loss: -0.4723 - val_accuracy: 0.6949\n",
            "Epoch 60/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0937 - accuracy: 0.5042 - val_loss: -0.5295 - val_accuracy: 0.6949\n",
            "Epoch 61/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: -1.1734 - accuracy: 0.4454 - val_loss: -0.9917 - val_accuracy: 0.4068\n",
            "Epoch 62/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.9049 - accuracy: 0.3950 - val_loss: -1.7105 - val_accuracy: 0.4068\n",
            "Epoch 63/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: -1.0580 - accuracy: 0.4118 - val_loss: -0.1917 - val_accuracy: 0.7119\n",
            "Epoch 64/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6369 - accuracy: 0.4622 - val_loss: -0.9631 - val_accuracy: 0.4068\n",
            "Epoch 65/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: -0.5847 - accuracy: 0.4118 - val_loss: -1.4284 - val_accuracy: 0.6441\n",
            "Epoch 66/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -0.7582 - accuracy: 0.4370 - val_loss: -1.9694 - val_accuracy: 0.4068\n",
            "Epoch 67/150\n",
            "5/5 [==============================] - 0s 22ms/step - loss: -0.0949 - accuracy: 0.3950 - val_loss: -0.0536 - val_accuracy: 0.4068\n",
            "Epoch 68/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5207 - accuracy: 0.3950 - val_loss: -1.6459 - val_accuracy: 0.4068\n",
            "Epoch 69/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: -2.1643 - accuracy: 0.4034 - val_loss: -0.2081 - val_accuracy: 0.4068\n",
            "Epoch 70/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.8640 - accuracy: 0.3950 - val_loss: -0.8018 - val_accuracy: 0.4068\n",
            "Epoch 71/150\n",
            "5/5 [==============================] - 0s 22ms/step - loss: -1.3884 - accuracy: 0.3950 - val_loss: -0.4091 - val_accuracy: 0.4068\n",
            "Epoch 72/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: -1.2059 - accuracy: 0.4286 - val_loss: -1.9714 - val_accuracy: 0.4237\n",
            "Epoch 73/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: -2.7429 - accuracy: 0.4034 - val_loss: -2.2917 - val_accuracy: 0.4068\n",
            "Epoch 74/150\n",
            "5/5 [==============================] - 0s 21ms/step - loss: -2.6160 - accuracy: 0.4454 - val_loss: -2.5807 - val_accuracy: 0.4576\n",
            "Epoch 75/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: -2.3458 - accuracy: 0.4202 - val_loss: -2.4227 - val_accuracy: 0.4237\n",
            "Epoch 76/150\n",
            "5/5 [==============================] - 0s 23ms/step - loss: -1.8688 - accuracy: 0.4454 - val_loss: -2.3959 - val_accuracy: 0.6780\n",
            "Epoch 77/150\n",
            "5/5 [==============================] - 0s 21ms/step - loss: -1.7610 - accuracy: 0.4958 - val_loss: -2.4971 - val_accuracy: 0.6780\n",
            "Epoch 78/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: -1.5155 - accuracy: 0.4370 - val_loss: -2.5315 - val_accuracy: 0.4746\n",
            "Epoch 79/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -3.7023 - accuracy: 0.3950 - val_loss: -0.2530 - val_accuracy: 0.4068\n",
            "Epoch 80/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.4637 - accuracy: 0.4286 - val_loss: -1.7728 - val_accuracy: 0.4068\n",
            "Epoch 81/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -1.8485 - accuracy: 0.4370 - val_loss: -1.4402 - val_accuracy: 0.6949\n",
            "Epoch 82/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.4521 - accuracy: 0.4370 - val_loss: -1.5593 - val_accuracy: 0.6441\n",
            "Epoch 83/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -0.0046 - accuracy: 0.4706 - val_loss: -0.6313 - val_accuracy: 0.7119\n",
            "Epoch 84/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: -0.7911 - accuracy: 0.4790 - val_loss: -0.7256 - val_accuracy: 0.4068\n",
            "Epoch 85/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.4370 - val_loss: -2.6339 - val_accuracy: 0.4746\n",
            "Epoch 86/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.2535 - accuracy: 0.4454 - val_loss: -3.5476 - val_accuracy: 0.6610\n",
            "Epoch 87/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -2.5086 - accuracy: 0.5126 - val_loss: -4.5963 - val_accuracy: 0.4068\n",
            "Epoch 88/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: -1.2834 - accuracy: 0.4538 - val_loss: -2.8007 - val_accuracy: 0.6780\n",
            "Epoch 89/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -2.8679 - accuracy: 0.5210 - val_loss: -4.2163 - val_accuracy: 0.4068\n",
            "Epoch 90/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -2.1105 - accuracy: 0.4034 - val_loss: -0.6159 - val_accuracy: 0.6610\n",
            "Epoch 91/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -1.0388 - accuracy: 0.4958 - val_loss: -2.0257 - val_accuracy: 0.6610\n",
            "Epoch 92/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -1.9696 - accuracy: 0.4370 - val_loss: -1.7671 - val_accuracy: 0.4068\n",
            "Epoch 93/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -2.3454 - accuracy: 0.3950 - val_loss: -2.6582 - val_accuracy: 0.4068\n",
            "Epoch 94/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: -1.4645 - accuracy: 0.4034 - val_loss: -1.7475 - val_accuracy: 0.4068\n",
            "Epoch 95/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -1.7073 - accuracy: 0.3866 - val_loss: -0.8286 - val_accuracy: 0.4068\n",
            "Epoch 96/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.1360 - accuracy: 0.3950 - val_loss: -3.2178 - val_accuracy: 0.4068\n",
            "Epoch 97/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -2.1555 - accuracy: 0.3866 - val_loss: -2.5709 - val_accuracy: 0.4068\n",
            "Epoch 98/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -3.3561 - accuracy: 0.3950 - val_loss: 0.1989 - val_accuracy: 0.4068\n",
            "Epoch 99/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3050 - accuracy: 0.3950 - val_loss: -2.5194 - val_accuracy: 0.4068\n",
            "Epoch 100/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.6145 - accuracy: 0.3950 - val_loss: -0.6601 - val_accuracy: 0.4068\n",
            "Epoch 101/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.5790 - accuracy: 0.3950 - val_loss: -0.4041 - val_accuracy: 0.4068\n",
            "Epoch 102/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.8425 - accuracy: 0.3950 - val_loss: -2.9253 - val_accuracy: 0.4068\n",
            "Epoch 103/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -5.4035 - accuracy: 0.3950 - val_loss: -3.3706 - val_accuracy: 0.4068\n",
            "Epoch 104/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -0.2596 - accuracy: 0.3950 - val_loss: 0.1824 - val_accuracy: 0.4068\n",
            "Epoch 105/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1812 - accuracy: 0.3950 - val_loss: -0.4211 - val_accuracy: 0.4068\n",
            "Epoch 106/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -1.7507 - accuracy: 0.3950 - val_loss: -3.7456 - val_accuracy: 0.4068\n",
            "Epoch 107/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.6844 - accuracy: 0.3950 - val_loss: -0.0347 - val_accuracy: 0.4068\n",
            "Epoch 108/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0737 - accuracy: 0.3950 - val_loss: -0.9223 - val_accuracy: 0.4068\n",
            "Epoch 109/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -1.5695 - accuracy: 0.3950 - val_loss: -2.8927 - val_accuracy: 0.4068\n",
            "Epoch 110/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -2.4162 - accuracy: 0.3950 - val_loss: -4.5149 - val_accuracy: 0.4068\n",
            "Epoch 111/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.4785 - accuracy: 0.3950 - val_loss: -0.2067 - val_accuracy: 0.4068\n",
            "Epoch 112/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -0.1501 - accuracy: 0.3950 - val_loss: 0.2399 - val_accuracy: 0.4068\n",
            "Epoch 113/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0899 - accuracy: 0.3950 - val_loss: -0.3027 - val_accuracy: 0.4068\n",
            "Epoch 114/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.3866 - val_loss: -0.3206 - val_accuracy: 0.4068\n",
            "Epoch 115/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1861 - accuracy: 0.3950 - val_loss: -0.1822 - val_accuracy: 0.4068\n",
            "Epoch 116/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1900 - accuracy: 0.3950 - val_loss: -0.1544 - val_accuracy: 0.4068\n",
            "Epoch 117/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -0.2369 - accuracy: 0.3950 - val_loss: 0.1820 - val_accuracy: 0.4068\n",
            "Epoch 118/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1767 - accuracy: 0.3950 - val_loss: -1.7343 - val_accuracy: 0.4068\n",
            "Epoch 119/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.4590 - accuracy: 0.3950 - val_loss: -0.8811 - val_accuracy: 0.4068\n",
            "Epoch 120/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.5118 - accuracy: 0.3950 - val_loss: -1.2759 - val_accuracy: 0.4068\n",
            "Epoch 121/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -1.4133 - accuracy: 0.3950 - val_loss: 1.9100 - val_accuracy: 0.4068\n",
            "Epoch 122/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8899 - accuracy: 0.3950 - val_loss: -1.9497 - val_accuracy: 0.4068\n",
            "Epoch 123/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -0.8539 - accuracy: 0.3950 - val_loss: -2.1270 - val_accuracy: 0.4068\n",
            "Epoch 124/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -0.9838 - accuracy: 0.3950 - val_loss: -0.2113 - val_accuracy: 0.4068\n",
            "Epoch 125/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -0.9402 - accuracy: 0.3950 - val_loss: -1.8310 - val_accuracy: 0.4068\n",
            "Epoch 126/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.2730 - accuracy: 0.3950 - val_loss: -2.2765 - val_accuracy: 0.4068\n",
            "Epoch 127/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.9148 - accuracy: 0.3950 - val_loss: -1.5423 - val_accuracy: 0.4068\n",
            "Epoch 128/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -1.8034 - accuracy: 0.3866 - val_loss: -1.3892 - val_accuracy: 0.4068\n",
            "Epoch 129/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: -0.1853 - accuracy: 0.3950 - val_loss: -0.4138 - val_accuracy: 0.4068\n",
            "Epoch 130/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1468 - accuracy: 0.3950 - val_loss: 0.6315 - val_accuracy: 0.4068\n",
            "Epoch 131/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6476 - accuracy: 0.3950 - val_loss: 0.6301 - val_accuracy: 0.4068\n",
            "Epoch 132/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6395 - accuracy: 0.3950 - val_loss: 0.6271 - val_accuracy: 0.4068\n",
            "Epoch 133/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6368 - accuracy: 0.3950 - val_loss: 0.6211 - val_accuracy: 0.4068\n",
            "Epoch 134/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.3950 - val_loss: 0.6170 - val_accuracy: 0.4068\n",
            "Epoch 135/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6199 - accuracy: 0.3950 - val_loss: 0.6017 - val_accuracy: 0.4068\n",
            "Epoch 136/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5603 - accuracy: 0.3950 - val_loss: 0.5735 - val_accuracy: 0.4068\n",
            "Epoch 137/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5663 - accuracy: 0.3950 - val_loss: 0.5281 - val_accuracy: 0.4068\n",
            "Epoch 138/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5962 - accuracy: 0.3950 - val_loss: 0.4646 - val_accuracy: 0.4068\n",
            "Epoch 139/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5431 - accuracy: 0.3950 - val_loss: 0.3203 - val_accuracy: 0.4068\n",
            "Epoch 140/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.3950 - val_loss: -0.4516 - val_accuracy: 0.4068\n",
            "Epoch 141/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -0.4942 - accuracy: 0.3950 - val_loss: -1.9299 - val_accuracy: 0.4068\n",
            "Epoch 142/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.4058 - accuracy: 0.3950 - val_loss: -1.8813 - val_accuracy: 0.4068\n",
            "Epoch 143/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.6954 - accuracy: 0.3950 - val_loss: -1.3305 - val_accuracy: 0.4068\n",
            "Epoch 144/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: -0.5705 - accuracy: 0.3950 - val_loss: -1.7785 - val_accuracy: 0.4068\n",
            "Epoch 145/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -0.5771 - accuracy: 0.3950 - val_loss: -2.6322 - val_accuracy: 0.4068\n",
            "Epoch 146/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: -2.1700 - accuracy: 0.3950 - val_loss: -0.7068 - val_accuracy: 0.4068\n",
            "Epoch 147/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: -0.4378 - accuracy: 0.3866 - val_loss: -0.5149 - val_accuracy: 0.4068\n",
            "Epoch 148/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2220 - accuracy: 0.3950 - val_loss: -2.9264 - val_accuracy: 0.4068\n",
            "Epoch 149/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: -1.8861 - accuracy: 0.3950 - val_loss: -2.9284 - val_accuracy: 0.4068\n",
            "Epoch 150/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: -2.8177 - accuracy: 0.3950 - val_loss: -3.2164 - val_accuracy: 0.4068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show the application of a drop-based learning rate schedule"
      ],
      "metadata": {
        "id": "Tn2pAdzp8IGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Define the learning rate schedule function (as explained before)\n",
        "def drop_based_learning_rate(epoch, initial_learning_rate=0.1, drop_rate=0.1, drop_interval=5):\n",
        "    if epoch % drop_interval == 0 and epoch > 0:\n",
        "        return initial_learning_rate * (1 - drop_rate)\n",
        "    else:\n",
        "        return initial_learning_rate\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.33, random_state=42)\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))  #=\n",
        "\n",
        "\n",
        "initial_learning_rate = 0.1\n",
        "drop_rate = 0.1\n",
        "drop_interval = 5\n",
        "\n",
        "\n",
        "optimizer = SGD(learning_rate=drop_based_learning_rate(epoch=0, initial_learning_rate=initial_learning_rate, drop_rate=drop_rate, drop_interval=drop_interval))\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 150\n",
        "batch_size = 28\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3BJdjIME6MpT",
        "outputId": "c5cc6589-27f1-44ec-d634-4cb801b00c79"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "5/5 [==============================] - 1s 64ms/step - loss: 15989591771839463424.0000 - accuracy: 0.3697 - val_loss: 695433035776.0000 - val_accuracy: 0.3390\n",
            "Epoch 2/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 145944772608.0000 - accuracy: 0.4034 - val_loss: 0.5521 - val_accuracy: 0.4068\n",
            "Epoch 3/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5200 - accuracy: 0.3950 - val_loss: 0.5034 - val_accuracy: 0.4068\n",
            "Epoch 4/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4711 - accuracy: 0.3950 - val_loss: 0.4653 - val_accuracy: 0.4068\n",
            "Epoch 5/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4314 - accuracy: 0.3950 - val_loss: 0.4354 - val_accuracy: 0.4068\n",
            "Epoch 6/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3974 - accuracy: 0.3950 - val_loss: 0.4111 - val_accuracy: 0.4068\n",
            "Epoch 7/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.3950 - val_loss: 0.3875 - val_accuracy: 0.4068\n",
            "Epoch 8/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3453 - accuracy: 0.3950 - val_loss: 0.3724 - val_accuracy: 0.4068\n",
            "Epoch 9/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3293 - accuracy: 0.3950 - val_loss: 0.3523 - val_accuracy: 0.4068\n",
            "Epoch 10/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3039 - accuracy: 0.3950 - val_loss: 0.3445 - val_accuracy: 0.4068\n",
            "Epoch 11/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2953 - accuracy: 0.3950 - val_loss: 0.3416 - val_accuracy: 0.4068\n",
            "Epoch 12/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2912 - accuracy: 0.3950 - val_loss: 0.3309 - val_accuracy: 0.4068\n",
            "Epoch 13/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2783 - accuracy: 0.3950 - val_loss: 0.3232 - val_accuracy: 0.4068\n",
            "Epoch 14/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2681 - accuracy: 0.3950 - val_loss: 0.3204 - val_accuracy: 0.4068\n",
            "Epoch 15/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2646 - accuracy: 0.3950 - val_loss: 0.3162 - val_accuracy: 0.4068\n",
            "Epoch 16/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2580 - accuracy: 0.3950 - val_loss: 0.3112 - val_accuracy: 0.4068\n",
            "Epoch 17/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2518 - accuracy: 0.3950 - val_loss: 0.3098 - val_accuracy: 0.4068\n",
            "Epoch 18/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2496 - accuracy: 0.3950 - val_loss: 0.3065 - val_accuracy: 0.4068\n",
            "Epoch 19/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2444 - accuracy: 0.3950 - val_loss: 0.3037 - val_accuracy: 0.4068\n",
            "Epoch 20/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2400 - accuracy: 0.3950 - val_loss: 0.3019 - val_accuracy: 0.4068\n",
            "Epoch 21/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2385 - accuracy: 0.3950 - val_loss: 0.3008 - val_accuracy: 0.4068\n",
            "Epoch 22/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2361 - accuracy: 0.3950 - val_loss: 0.2985 - val_accuracy: 0.4068\n",
            "Epoch 23/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2310 - accuracy: 0.3950 - val_loss: 0.2962 - val_accuracy: 0.4068\n",
            "Epoch 24/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2273 - accuracy: 0.3950 - val_loss: 0.2941 - val_accuracy: 0.4068\n",
            "Epoch 25/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2228 - accuracy: 0.3950 - val_loss: 0.2930 - val_accuracy: 0.4068\n",
            "Epoch 26/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2203 - accuracy: 0.3950 - val_loss: 0.2924 - val_accuracy: 0.4068\n",
            "Epoch 27/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2183 - accuracy: 0.3950 - val_loss: 0.2916 - val_accuracy: 0.4068\n",
            "Epoch 28/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2164 - accuracy: 0.3950 - val_loss: 0.2912 - val_accuracy: 0.4068\n",
            "Epoch 29/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2154 - accuracy: 0.3950 - val_loss: 0.2908 - val_accuracy: 0.4068\n",
            "Epoch 30/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2132 - accuracy: 0.3950 - val_loss: 0.2904 - val_accuracy: 0.4068\n",
            "Epoch 31/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2115 - accuracy: 0.3950 - val_loss: 0.2903 - val_accuracy: 0.4068\n",
            "Epoch 32/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2099 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 33/150\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.2088 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 34/150\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2094 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 35/150\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2092 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 36/150\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2092 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 37/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2109 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 38/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2091 - accuracy: 0.3950 - val_loss: 0.2902 - val_accuracy: 0.4068\n",
            "Epoch 39/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2074 - accuracy: 0.3950 - val_loss: 0.2904 - val_accuracy: 0.4068\n",
            "Epoch 40/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2064 - accuracy: 0.3950 - val_loss: 0.2907 - val_accuracy: 0.4068\n",
            "Epoch 41/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.3950 - val_loss: 0.2904 - val_accuracy: 0.4068\n",
            "Epoch 42/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2067 - accuracy: 0.3950 - val_loss: 0.2906 - val_accuracy: 0.4068\n",
            "Epoch 43/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2060 - accuracy: 0.3950 - val_loss: 0.2907 - val_accuracy: 0.4068\n",
            "Epoch 44/150\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2056 - accuracy: 0.3950 - val_loss: 0.2906 - val_accuracy: 0.4068\n",
            "Epoch 45/150\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.2059 - accuracy: 0.3950 - val_loss: 0.2910 - val_accuracy: 0.4068\n",
            "Epoch 46/150\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2060 - accuracy: 0.3950 - val_loss: 0.2913 - val_accuracy: 0.4068\n",
            "Epoch 47/150\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2048 - accuracy: 0.3950 - val_loss: 0.2908 - val_accuracy: 0.4068\n",
            "Epoch 48/150\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2065 - accuracy: 0.3950 - val_loss: 0.2907 - val_accuracy: 0.4068\n",
            "Epoch 49/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2055 - accuracy: 0.3950 - val_loss: 0.2906 - val_accuracy: 0.4068\n",
            "Epoch 50/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.3950 - val_loss: 0.2908 - val_accuracy: 0.4068\n",
            "Epoch 51/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2065 - accuracy: 0.3950 - val_loss: 0.2911 - val_accuracy: 0.4068\n",
            "Epoch 52/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2045 - accuracy: 0.3950 - val_loss: 0.2914 - val_accuracy: 0.4068\n",
            "Epoch 53/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2041 - accuracy: 0.3950 - val_loss: 0.2910 - val_accuracy: 0.4068\n",
            "Epoch 54/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2052 - accuracy: 0.3950 - val_loss: 0.2910 - val_accuracy: 0.4068\n",
            "Epoch 55/150\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.2048 - accuracy: 0.3950 - val_loss: 0.2913 - val_accuracy: 0.4068\n",
            "Epoch 56/150\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.2040 - accuracy: 0.3950 - val_loss: 0.2913 - val_accuracy: 0.4068\n",
            "Epoch 57/150\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2046 - accuracy: 0.3950 - val_loss: 0.2915 - val_accuracy: 0.4068\n",
            "Epoch 58/150\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.2047 - accuracy: 0.3950 - val_loss: 0.2914 - val_accuracy: 0.4068\n",
            "Epoch 59/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2035 - accuracy: 0.3950 - val_loss: 0.2913 - val_accuracy: 0.4068\n",
            "Epoch 60/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2058 - accuracy: 0.3950 - val_loss: 0.2915 - val_accuracy: 0.4068\n",
            "Epoch 61/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2054 - accuracy: 0.3950 - val_loss: 0.2922 - val_accuracy: 0.4068\n",
            "Epoch 62/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2029 - accuracy: 0.3950 - val_loss: 0.2928 - val_accuracy: 0.4068\n",
            "Epoch 63/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2030 - accuracy: 0.3950 - val_loss: 0.2928 - val_accuracy: 0.4068\n",
            "Epoch 64/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2028 - accuracy: 0.3950 - val_loss: 0.2921 - val_accuracy: 0.4068\n",
            "Epoch 65/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2033 - accuracy: 0.3950 - val_loss: 0.2923 - val_accuracy: 0.4068\n",
            "Epoch 66/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2051 - accuracy: 0.3950 - val_loss: 0.2923 - val_accuracy: 0.4068\n",
            "Epoch 67/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2029 - accuracy: 0.3950 - val_loss: 0.2928 - val_accuracy: 0.4068\n",
            "Epoch 68/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2022 - accuracy: 0.3950 - val_loss: 0.2924 - val_accuracy: 0.4068\n",
            "Epoch 69/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2025 - accuracy: 0.3950 - val_loss: 0.2924 - val_accuracy: 0.4068\n",
            "Epoch 70/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 0.3950 - val_loss: 0.2921 - val_accuracy: 0.4068\n",
            "Epoch 71/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2055 - accuracy: 0.3950 - val_loss: 0.2918 - val_accuracy: 0.4068\n",
            "Epoch 72/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2056 - accuracy: 0.3950 - val_loss: 0.2922 - val_accuracy: 0.4068\n",
            "Epoch 73/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2033 - accuracy: 0.3950 - val_loss: 0.2922 - val_accuracy: 0.4068\n",
            "Epoch 74/150\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.2033 - accuracy: 0.3950 - val_loss: 0.2926 - val_accuracy: 0.4068\n",
            "Epoch 75/150\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2026 - accuracy: 0.3950 - val_loss: 0.2934 - val_accuracy: 0.4068\n",
            "Epoch 76/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2019 - accuracy: 0.3950 - val_loss: 0.2937 - val_accuracy: 0.4068\n",
            "Epoch 77/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2026 - accuracy: 0.3950 - val_loss: 0.2949 - val_accuracy: 0.4068\n",
            "Epoch 78/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2020 - accuracy: 0.3950 - val_loss: 0.2954 - val_accuracy: 0.4068\n",
            "Epoch 79/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.2956 - val_accuracy: 0.4068\n",
            "Epoch 80/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2011 - accuracy: 0.3950 - val_loss: 0.2966 - val_accuracy: 0.4068\n",
            "Epoch 81/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2006 - accuracy: 0.3950 - val_loss: 0.2962 - val_accuracy: 0.4068\n",
            "Epoch 82/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.2956 - val_accuracy: 0.4068\n",
            "Epoch 83/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2012 - accuracy: 0.3950 - val_loss: 0.2967 - val_accuracy: 0.4068\n",
            "Epoch 84/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2019 - accuracy: 0.3950 - val_loss: 0.2966 - val_accuracy: 0.4068\n",
            "Epoch 85/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2032 - accuracy: 0.3950 - val_loss: 0.2964 - val_accuracy: 0.4068\n",
            "Epoch 86/150\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2005 - accuracy: 0.3950 - val_loss: 0.2958 - val_accuracy: 0.4068\n",
            "Epoch 87/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2006 - accuracy: 0.3950 - val_loss: 0.2960 - val_accuracy: 0.4068\n",
            "Epoch 88/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2006 - accuracy: 0.3950 - val_loss: 0.2959 - val_accuracy: 0.4068\n",
            "Epoch 89/150\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2012 - accuracy: 0.3950 - val_loss: 0.2955 - val_accuracy: 0.4068\n",
            "Epoch 90/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2022 - accuracy: 0.3950 - val_loss: 0.2960 - val_accuracy: 0.4068\n",
            "Epoch 91/150\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2021 - accuracy: 0.3950 - val_loss: 0.2956 - val_accuracy: 0.4068\n",
            "Epoch 92/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.2964 - val_accuracy: 0.4068\n",
            "Epoch 93/150\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.2972 - val_accuracy: 0.4068\n",
            "Epoch 94/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2016 - accuracy: 0.3950 - val_loss: 0.2971 - val_accuracy: 0.4068\n",
            "Epoch 95/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2005 - accuracy: 0.3950 - val_loss: 0.2979 - val_accuracy: 0.4068\n",
            "Epoch 96/150\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2005 - accuracy: 0.3950 - val_loss: 0.2972 - val_accuracy: 0.4068\n",
            "Epoch 97/150\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.2980 - val_accuracy: 0.4068\n",
            "Epoch 98/150\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2007 - accuracy: 0.3950 - val_loss: 0.2963 - val_accuracy: 0.4068\n",
            "Epoch 99/150\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.2962 - val_accuracy: 0.4068\n",
            "Epoch 100/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2023 - accuracy: 0.3950 - val_loss: 0.2970 - val_accuracy: 0.4068\n",
            "Epoch 101/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2007 - accuracy: 0.3950 - val_loss: 0.2972 - val_accuracy: 0.4068\n",
            "Epoch 102/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2007 - accuracy: 0.3950 - val_loss: 0.2990 - val_accuracy: 0.4068\n",
            "Epoch 103/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2003 - accuracy: 0.3950 - val_loss: 0.2982 - val_accuracy: 0.4068\n",
            "Epoch 104/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.2987 - val_accuracy: 0.4068\n",
            "Epoch 105/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2031 - accuracy: 0.3950 - val_loss: 0.3006 - val_accuracy: 0.4068\n",
            "Epoch 106/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.3000 - val_accuracy: 0.4068\n",
            "Epoch 107/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2004 - accuracy: 0.3950 - val_loss: 0.3005 - val_accuracy: 0.4068\n",
            "Epoch 108/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2006 - accuracy: 0.3950 - val_loss: 0.3006 - val_accuracy: 0.4068\n",
            "Epoch 109/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2000 - accuracy: 0.3950 - val_loss: 0.2997 - val_accuracy: 0.4068\n",
            "Epoch 110/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1998 - accuracy: 0.3950 - val_loss: 0.2995 - val_accuracy: 0.4068\n",
            "Epoch 111/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2001 - accuracy: 0.3950 - val_loss: 0.3003 - val_accuracy: 0.4068\n",
            "Epoch 112/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2004 - accuracy: 0.3950 - val_loss: 0.3012 - val_accuracy: 0.4068\n",
            "Epoch 113/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.3021 - val_accuracy: 0.4068\n",
            "Epoch 114/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2000 - accuracy: 0.3950 - val_loss: 0.3022 - val_accuracy: 0.4068\n",
            "Epoch 115/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2006 - accuracy: 0.3950 - val_loss: 0.3027 - val_accuracy: 0.4068\n",
            "Epoch 116/150\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2003 - accuracy: 0.3950 - val_loss: 0.3032 - val_accuracy: 0.4068\n",
            "Epoch 117/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2003 - accuracy: 0.3950 - val_loss: 0.3037 - val_accuracy: 0.4068\n",
            "Epoch 118/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2002 - accuracy: 0.3950 - val_loss: 0.3038 - val_accuracy: 0.4068\n",
            "Epoch 119/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2010 - accuracy: 0.3950 - val_loss: 0.3030 - val_accuracy: 0.4068\n",
            "Epoch 120/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2005 - accuracy: 0.3950 - val_loss: 0.3023 - val_accuracy: 0.4068\n",
            "Epoch 121/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2002 - accuracy: 0.3950 - val_loss: 0.3028 - val_accuracy: 0.4068\n",
            "Epoch 122/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2000 - accuracy: 0.3950 - val_loss: 0.3021 - val_accuracy: 0.4068\n",
            "Epoch 123/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1999 - accuracy: 0.3950 - val_loss: 0.3022 - val_accuracy: 0.4068\n",
            "Epoch 124/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2006 - accuracy: 0.3950 - val_loss: 0.3019 - val_accuracy: 0.4068\n",
            "Epoch 125/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2007 - accuracy: 0.3950 - val_loss: 0.3028 - val_accuracy: 0.4068\n",
            "Epoch 126/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2003 - accuracy: 0.3950 - val_loss: 0.3037 - val_accuracy: 0.4068\n",
            "Epoch 127/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2005 - accuracy: 0.3950 - val_loss: 0.3041 - val_accuracy: 0.4068\n",
            "Epoch 128/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.3034 - val_accuracy: 0.4068\n",
            "Epoch 129/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2000 - accuracy: 0.3950 - val_loss: 0.3034 - val_accuracy: 0.4068\n",
            "Epoch 130/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2013 - accuracy: 0.3950 - val_loss: 0.3044 - val_accuracy: 0.4068\n",
            "Epoch 131/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2003 - accuracy: 0.3950 - val_loss: 0.3057 - val_accuracy: 0.4068\n",
            "Epoch 132/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2007 - accuracy: 0.3950 - val_loss: 0.3071 - val_accuracy: 0.4068\n",
            "Epoch 133/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2011 - accuracy: 0.3950 - val_loss: 0.3071 - val_accuracy: 0.4068\n",
            "Epoch 134/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2025 - accuracy: 0.3950 - val_loss: 0.3080 - val_accuracy: 0.4068\n",
            "Epoch 135/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2010 - accuracy: 0.3950 - val_loss: 0.3080 - val_accuracy: 0.4068\n",
            "Epoch 136/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2020 - accuracy: 0.3950 - val_loss: 0.3066 - val_accuracy: 0.4068\n",
            "Epoch 137/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.3075 - val_accuracy: 0.4068\n",
            "Epoch 138/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2012 - accuracy: 0.3950 - val_loss: 0.3075 - val_accuracy: 0.4068\n",
            "Epoch 139/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2021 - accuracy: 0.3950 - val_loss: 0.3079 - val_accuracy: 0.4068\n",
            "Epoch 140/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.3075 - val_accuracy: 0.4068\n",
            "Epoch 141/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2013 - accuracy: 0.3950 - val_loss: 0.3084 - val_accuracy: 0.4068\n",
            "Epoch 142/150\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2019 - accuracy: 0.3950 - val_loss: 0.3088 - val_accuracy: 0.4068\n",
            "Epoch 143/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2009 - accuracy: 0.3950 - val_loss: 0.3088 - val_accuracy: 0.4068\n",
            "Epoch 144/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.3950 - val_loss: 0.3097 - val_accuracy: 0.4068\n",
            "Epoch 145/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 0.3950 - val_loss: 0.3111 - val_accuracy: 0.4068\n",
            "Epoch 146/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2013 - accuracy: 0.3950 - val_loss: 0.3105 - val_accuracy: 0.4068\n",
            "Epoch 147/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2020 - accuracy: 0.3950 - val_loss: 0.3114 - val_accuracy: 0.4068\n",
            "Epoch 148/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2021 - accuracy: 0.3950 - val_loss: 0.3090 - val_accuracy: 0.4068\n",
            "Epoch 149/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.3950 - val_loss: 0.3085 - val_accuracy: 0.4068\n",
            "Epoch 150/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2008 - accuracy: 0.3950 - val_loss: 0.3070 - val_accuracy: 0.4068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion: Based on the output and the difference of the accuracy between the previous learning the way how I approach the data is very different from the previous acitivities and based on that I think that the differnece are being affected on how the learning of each of the model is happening but also how I approached and treated the dataset."
      ],
      "metadata": {
        "id": "JsDrD-QB8e9E"
      }
    }
  ]
}